{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'E:\\ML_data\\wiseOcean\\DF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "# 把读取所有数据的函数放在单独的python文件中，是为了解决多线程问题在jupyter notebook无法运行的问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_all_data.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_train_file(filename=None):\n",
    "    # 替换数据存放的路径\n",
    "    Path = \"E:/ML_data/wiseOcean/\"\n",
    "    return pd.read_csv(Path + filename,encoding=\"utf-8\")\n",
    "\n",
    "def read_test_file(filename=None):\n",
    "    # 替换数据存放的路径\n",
    "    Path = \"E:/ML_data/wiseOcean/\"\n",
    "    return pd.read_csv(Path + filename,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load_Save_Data():\n",
    "    def __init__(self,file_name=None):\n",
    "        self.filename = file_name\n",
    "\n",
    "    def load_data(self,Path=None):\n",
    "        if Path is None:\n",
    "            assert self.filename is not None,\"Invalid Path....\"\n",
    "        else:\n",
    "            self.filename = Path\n",
    "        with open(self.filename,\"wb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "    def save_data(self,data,path):\n",
    "        if path is None:\n",
    "            assert self.filename is not None,\"Invalid path....\"\n",
    "        else:\n",
    "            self.filename = path\n",
    "        with open(self.filename,\"wb\") as f:\n",
    "            pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义读取数据的函数\n",
    "def read_data(Path,Kind=\"\"):\n",
    "    \"\"\"\n",
    "    :param Path:待读取数据的存放路径\n",
    "    :param Kind:'train' of 'test'\n",
    "    \"\"\"\n",
    "\n",
    "    # 替换成数据存放的路径\n",
    "    filenames = os.listdir(Path)\n",
    "    print(\"\\n@Read Data From\"+Path+\".........................\")\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        data_total = list(tqdm(pool.map(read_train_file if Kind == \"train\" else \n",
    "                                        read_test_file,filenames),total=len(filenames)))\n",
    "    print(\"\\n@End Read total Data............................\")\n",
    "    load_save = Load_Save_Data()\n",
    "    if Kind == \"train\":\n",
    "        load_save.save_data(data_total,\"./data_tmp/total_data.pkl\")\n",
    "    return data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@Read Data FromE:/ML_data/wiseOcean/.........................\n"
     ]
    }
   ],
   "source": [
    "# 训练数据读取\n",
    "\n",
    "# 存放数据的绝对路径\n",
    "train_path = \"E:/ML_data/wiseOcean/\"\n",
    "data_train = read_data(train_path,Kind=\"train\")\n",
    "data_train = pd.concat(data_train)\n",
    "\n",
    "# 测试数据读取\n",
    "\n",
    "# 存放数据的绝对路径\n",
    "test_path = \"E:/ML_data/wiseOcean/\"\n",
    "data_test = read_data(test_path,Kind=\"test\")\n",
    "data_test = pd.concat(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_info_rows = 2699639\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe([0.01,0.025,0.05,0.5,0.75,0.9,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(3).append(data_train.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {data_train.isnull().any().sum()} columns in train dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_fea = [col for col in data_train.columns if data_train[col].nunique() <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_fea_test = [col for col in data_test.columns if data_test[col].nunique() <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_fea_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(one_value_fea)} columns in train dataset with one unique value.')\n",
    "print(f'There are {len(one_value_fea_test)} columns in test dataset with one unique value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 把训练集的所有数据,根据类别存放到不同的数据文件中\n",
    "def get_diff_data():\n",
    "    Path = \"./data_tmp/total_data.pkl\"\n",
    "    with open(Path,\"rb\") as f:\n",
    "        total_data = pickle.load(f)\n",
    "\n",
    "    load_save = Load_Save_Data()\n",
    "\n",
    "    kind_data = [\"刺网\",\"围网\",\"拖网\"]\n",
    "    file_names = [\"ciwang_data.pkl\",\"weiwang_data.pkl\",\"tuowang_data.pkl\"]\n",
    "    for i,datax in enumerate(kind_data):\n",
    "        data_type =  [data for data in total_data if data[\"type\"].unique()[0] == datax]\n",
    "        load_save.save_data(data_type,\"./data_tmp/\" + file_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_diff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从存放某个轨迹类别的数据文件中，随机读取某个渔船的数据\n",
    "def get_random_one_traj(type=None):\n",
    "    \"\"\"\n",
    "    :param type:\"ciwang\",\"weiwang\" or \"tuowang\"\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(10)\n",
    "    path = \"./data_tmp/\"\n",
    "    with open(path + type + \".pkl\",\"rb\") as f1:\n",
    "        data = pickle.load(f1)\n",
    "    length = len(data)\n",
    "    index = np.random.choice(length)\n",
    "    return data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别从三个类别的数据文件中，随机读取某三个渔船的数据\n",
    "def get_random_three_traj(type=None):\n",
    "    \"\"\"\n",
    "    :param type:\"ciwang\",\"weiwang\" or \"tuowang\"\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(10)\n",
    "    path = \"./data_tmp/\"\n",
    "    with open(path + type + \".pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    data_arrange = np.arange(len(data)).tolist()\n",
    "    index = random.sample(data_arrange,3)\n",
    "    return data[index[0]],data[index[1]],data[index[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个类别中随机三个渔船的轨迹进行可视化\n",
    "def visualize_three_traj():\n",
    "    fig,axes = plt.subplots(nrows=3,ncols=3,figsize=(20,15))\n",
    "    plt.subplots_adjust(wspace=0.2,hspace=0.2)\n",
    "    # 对于每一个类别，随机选出刺网的三条轨迹进行可视化\n",
    "    lables = [\"ciwang\",\"weiwang\",\"tuowang\"]\n",
    "    for i,file_type in tqdm(enumerate([\"ciwang_data\",\"weiwang_data\",\"tuowang_data\"])):\n",
    "        data1, data2, data3 = get_random_three_traj(type=file_type)\n",
    "        for j, datax in enumerate([data1, data2, data3]):\n",
    "            x_data = datax[\"x\"].loc[-1:].values\n",
    "            y_data = datax[\"y\"].loc[-1:].values\n",
    "            axes[i][j - 1].scatter(x_data[0], y_data[0], label=\"start\", c=\"red\", s=10, marker=\"8\")\n",
    "            axes[i][j - 1].plot(x_data, y_data, label=lables[i])\n",
    "            axes[i][j - 1].scatter(x_data[len(x_data) - 1], y_data[len(y_data) - 1], label=\"end\", c=\"green\", s=10,\n",
    "                                   marker=\"v\")\n",
    "            axes[i][j - 1].grid(alpha=2)\n",
    "            axes[i][j - 1].legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_three_traj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选取某条数据，观察x坐标序列和y坐标序列的变化情况\n",
    "def visualize_one_traj_x_y():\n",
    "    fig,axes = plt.subplots(nrows=2,ncols=1,figsize=(10,8))\n",
    "    plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
    "\n",
    "    data1 = get_random_one_traj(type=\"weiwang_data\")\n",
    "    x = data1[\"x\"].loc[-1:]\n",
    "    x = x / 10000\n",
    "    \n",
    "    y = data1[\"y\"].loc[-1:]\n",
    "    y = y / 10000\n",
    "\n",
    "    arr1 = np.arange(len(x))\n",
    "    arr2 = np.arange(len(y))\n",
    "\n",
    "    axes[0].plot(arr1,x,label=\"x\")\n",
    "    axes[1].plot(arr2,y,label=\"y\")\n",
    "    axes[0].grid(alpha=3)\n",
    "    axes[0].legend(loc=\"best\")\n",
    "    axes[1].grid(alpha=3)\n",
    "    axes[1].legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_one_traj_x_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每类轨迹，随机选取某个渔船，可视化速度序列和方向序列\n",
    "def visualize_three_traj_speed_direction():\n",
    "    fig,axes = plt.subplots(nrows=3,ncols=2,figsize=(20,15))\n",
    "    plt.subplots_adjust(wspace=0.3,hspace=0.3)\n",
    "    # 随机选出刺网的三条轨迹进行可视化\n",
    "    file_types = [\"ciwang_data\",\"weiwang_data\",\"tuowang_data\"]\n",
    "    speed_types = [\"ciwang_speed\",\"weiwang_speed\",\"tuowang_speed\"]\n",
    "    doirections = [\"ciwang_direction\",\"weiwang_direction\",\"tuowang_direction\"]\n",
    "    colors = ['pink', 'lightblue', 'lightgreen']\n",
    "    for i,file_name in tqdm(enumerate(file_types)):\n",
    "        datax = get_random_one_traj(type=file_name)\n",
    "        x_data = datax[\"速度\"].loc[-1:].values\n",
    "        y_data = datax[\"方向\"].loc[-1:].values\n",
    "        axes[i][0].plot(range(len(x_data)), x_data, label=speed_types[i], color=colors[i])\n",
    "        axes[i][0].grid(alpha=2)\n",
    "        axes[i][0].legend(loc=\"best\")\n",
    "        axes[i][1].plot(range(len(y_data)), y_data, label=doirections[i], color=colors[i])\n",
    "        axes[i][1].grid(alpha=2)\n",
    "        axes[i][1].legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_three_traj_speed_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对某一特征进行数据统计\n",
    "def get_data_cummulation(type=None,path=None,kind=None,columns=None):\n",
    "    \"\"\"\n",
    "    :param type:\"ciwang\",\"weiwang\" or \"tuowang\"\n",
    "    :param path:存放数据路径\n",
    "    :param kind: '速度' or  '方向'\n",
    "    :param columns:与kind对应，'speed' or 'direction'\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = dict()\n",
    "    with open(path + type+\".pkl\",\"rb\") as file:\n",
    "        data_list = pickle.load(file)\n",
    "    for datax in tqdm(data_list):\n",
    "        data = datax[kind].values\n",
    "        for speed in data:\n",
    "            data_dict.setdefault(speed,0)\n",
    "            data_dict[speed] += 1\n",
    "    data_dict = dict(sorted(data_dict.items(),key=lambda x:x[0],reverse=False))\n",
    "    data_df = pd.DataFrame.from_dict(data_dict,columns=[columns],orient=\"index\")\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别得到速度和方向的分布数据\n",
    "def get_speed_and_direction_distribution_data(type=None):\n",
    "    \"\"\"\n",
    "    :param type:\"ciwang\",\"weiwang\" or \"tuowang\"\n",
    "    \"\"\"\n",
    "    \n",
    "    path = \"./data_tmp/\"\n",
    "    data_speed_df = get_data_cummulation(type=type, path=path,kind=\"速度\",columns=\"speed\")\n",
    "    data_direction_df = get_data_cummulation(type=type,path=path,kind=\"方向\",columns=\"direction\")\n",
    "    return data_speed_df,data_direction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化速度和方向的数据分布\n",
    "df_speeds = []\n",
    "df_directions = []\n",
    "\n",
    "\n",
    "def plot_speed_direction1_distribution():\n",
    "    plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "    file_types = [\"ciwang_data\", \"weiwang_data\", \"tuowang_data\"]\n",
    "    lables = [\"target==cw\", \"target==ww\", \"target==tw\"]\n",
    "    colors = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "    for i, filenames in enumerate(file_types):\n",
    "        df11, df21 = get_speed_and_direction_distribution_data(file_types[i])\n",
    "        plt.subplot(1,2,1)\n",
    "        ax1 = sns.kdeplot(df11[\"speed\"].values / 1000000, color=colors[i],shade=True)\n",
    "        plt.subplot(1,2,2)\n",
    "        ax3 = sns.kdeplot(df21[\"direction\"].values / 1000000, color=colors[i],shade=True)\n",
    "        df_speeds.append(df11)\n",
    "        df_directions.append(df21)\n",
    "    ax1.legend(lables)\n",
    "    ax1.set_xlabel(\"Speed\")\n",
    "    ax3.set_xlabel(\"Direction\")\n",
    "    ax3.legend(lables)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_speed_direction1_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用分位图对速度和方向的数据分布进行可视化\n",
    "def plot_speed_direction2_distribution():\n",
    "    fig,axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "    colors_box = ['pink', 'lightblue', 'lightgreen']\n",
    "\n",
    "    bplot1 = axes[0].boxplot([df_speeds[0][\"speed\"].values,df_speeds[1][\"speed\"].values,df_speeds[2][\"speed\"].values]\n",
    "                       , vert=True\n",
    "                       , patch_artist=True\n",
    "                       , labels=[\"cw\", \"ww\", \"tw\"])\n",
    "    bplot2 = axes[1].boxplot([df_directions[0][\"direction\"].values, df_directions[1][\"direction\"].values, df_directions[2][\"direction\"].values]\n",
    "                       , vert=True\n",
    "                       , patch_artist=True\n",
    "                       , labels=[\"cw\", \"ww\", \"tw\"])\n",
    "\n",
    "    for blpot in (bplot1,bplot2):\n",
    "        for patch,color in zip(blpot[\"boxes\"],colors_box):\n",
    "            patch.set_facecolor(color)\n",
    "\n",
    "    axes[0].set_title(\"speed\")\n",
    "    axes[1].set_title(\"direction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_speed_direction2_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
